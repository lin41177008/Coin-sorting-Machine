
<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
    <meta name="description" content="">
    <meta name="author" content="">

    <title>Coin Sorting Machine</title>

    <!-- Bootstrap core CSS -->
    <link href="dist/css/bootstrap.min.css" rel="stylesheet">

    <!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->
    <!-- <link href="../../assets/css/ie10-viewport-bug-workaround.css" rel="stylesheet"> -->

    <!-- Custom styles for this template -->
    <link href="starter-template.css" rel="stylesheet">

    <!-- Just for debugging purposes. Don't actually copy these 2 lines! -->
    <!--[if lt IE 9]><script src="../../assets/js/ie8-responsive-file-warning.js"></script><![endif]-->
    <!-- <script src="../../assets/js/ie-emulation-modes-warning.js"></script> -->

    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
      <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
  </head>

  <body>

    <nav class="navbar navbar-inverse navbar-fixed-top">
      <div class="container">
        <div class="navbar-header">
          <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </button>
          <a class="navbar-brand" href="#">Project name</a>
        </div>
        <div id="navbar" class="collapse navbar-collapse">
          <ul class="nav navbar-nav">
            <li class="active"><a href="#">Home</a></li>
            <li><a href="#intro">Introduction</a></li>
            <li><a href="#obj">Project Objective</a></li>
            <li><a href="#design">Design</a></li>
            <li><a href="#drawings">Drawings</a></li>
            <li><a href="#testing">Testing</a></li>
            <li><a href="#result">Result</a></li>
          </ul>
        </div><!--/.nav-collapse -->
      </div>
    </nav>

    <div class="container">

      <div class="starter-template">
        <h1>Computer Vision Based Coin Sorting Machine</h1>
        <p class="lead">Designed By:</br>Guangwei Chen(gc535), Shuheng Lin(sl2954)</p>
      </div>

      <hr>
      <div class="center-block">
          <iframe width="640" height="360" src="https://www.youtube.com/embed/eiQ7eE-1HMc" frameborder="0" allowfullscreen></iframe>
          <h4 style="text-align:center;">Demonstration Video</h4>
      </div>

      <hr id="intro">

      <div class="row">
          <div class="col-md-8" style="font-size:18px;">
              <h2><p style="text-align: justify;padding: 0px 30px;">Introduction</h2>
              <p style="text-align: justify;padding: 0px 30px;">The initial motivation of this project comes from the daily issue that encountered by many international students during their grocery shopping. There are many different kinds of coin used in the US.:  <b>quarter dollar, dime, 5 cents, 1 cent</b>, and international students often have a hard time when they are trying to use some of the change they got after grocery shopping. They can barely distinguish between 5 cent, 1 cent and 1 dim without taking a really close look at them. Thus, for this project, we propose a device that can do the job for us.</br></br> For this project, we were interested in using computer vision based technology along with image processing to design a sorting machine that can sort some common US coins automatically for us. The design was built on the Raspberry Pi platform with OpenCV. Thie device utilizes several image processing techniques to perform the coin classification. This device support speed control at users’ will, and provides general information, such as coin type, counts, and total value of a single round of operation instead of simply doing the sorting. By using this device, user can not only have a bunch of coins sorted in order, but also obtain a total value of the change been sorted. </p>
          </div>
          <div class="col-md-4" style="text-align:center; padding-top: 50px;">
             <img class="img-rounded" src="pics/project.jpg" alt="Generic placeholder image" width="330" height="390">
          </div>
      </div>

    <hr id='obj'>

      <div class="row">
          
          <img class="img-rounded" src="pics/coins.png" style="float:right; margin: 0px 70px;" alt="Generic placeholder image" width="240" height="240">
          

          <div class="col-md-8" style="font-size:18px;">
          <h2 style="padding-left: 25px;"> Project Objective:</h2>
          <ul>
              <li> The machine will be able to distinguish between one cents, 5 cents, dime, and quarter coins.</li>
              <li>The machine will be able to collect the sorted coins with a relatively high accuracy.</li>
              <li>The machine will keep track of the total value and the count of each kind after every operation.</li>
              <li>The device should support running speed control at any time at user’s will. </li>
              <li>The result of the detection (coin image) will be updated on the touch screen for users’ information.</li>
          </ul>
          </div>

      </div>

    <hr id='design'>

      <div style = "padding: 0px 0px 60px">
              <h1 style="text-align:center;padding: 0px">Design</h1>
              <h3 style="text-align:left;padding: 0px 280px;"> The Big Picture</h3>

              <div class="col-md-3" style="text-align:center;">
                <img class="img-rounded" src="pics/feed.jpg" alt="Generic placeholder image" width="200" height="200">
              </div>
              <div style="text-align:left;">
              <h4 style = "padding: 40px 30px 0px;">Feeding </h4>
                <p style="text-align: justify;padding: 0px 30px;"> There are two coin slots on two sides of the plate, and the rotating plate is mounted on a inclined surface. All the coins will be held in a "pocket" on the mounting surface, so when the slots on the rotating plate moves into the "pocket", it will carry up a coin fell in that slot and put it onto the conveyor belt. The speed of the rotating plate can be adjusted by the software to speed up or slow down the sorting process. </p>
              </div>
           
              
              <img class="img-rounded" style="float:right;padding: 0px 0px;" src="pics/sort.jpg" alt="Generic placeholder image" width="200" height="200">
              <h4 style="text-align:left;padding: 30px 280px 0px;">Sorting </h4>
              <div>          
                <p style="text-align: justify;padding: 0px 280px;"> The sorting operation of this design was entirely developed in software, where the captured image was processed and analyzed. For our design, the sorting algorithm was developed with using OpenCV and integrated some basic computer vision techniques: We integrated canny edge detection, houghcicrle transform, HSV color space transform, area calculation, color code extraction, etc. The sorting software output the prediction result back to the hardware control, which handles the coin collection.  </p>
              </div>



              <div class="col-md-3" style="text-align:center;">
                <img class="img-rounded" src="pics/collect.jpg" alt="Generic placeholder image" width="200" height="200">
              </div>
              <div style="text-align:left;">
              <h4 style = "padding: 40px 30px 0px;">Collecting </h4>
                <p style="text-align: justify;padding: 0px 30px;"> The collecting mechanism of this project was built with a rotating collector, which has four well separated compartments. After analyzing the captured frame, the sorting module will output the result back to the hardware control module, which drives the collecting mechanism of this design. Ideally, after recognizing the coin object, a corresponding compartment will be moved right under the conveyor belt to catch the falling coin.  </p>
              </div>

              <div style="text-align:left;">
              <h3 style = "padding: 50px 30px 0px;">Detail </h3>
                <img class="img-rounded" src="pics/display.jpg" style="float: right; margin: 50px 50px;" alt="Generic placeholder image" width="480" height="360">
                <p style="text-align: justify;padding: 0px 30px;"> <b>Touch Screen User Interface and Button Control</b> </p>
                <p style="text-align: justify;padding: 0px 30px;">In the beginning, we had two general concepts of moving coins during the sorting process: </p>
                <p style="text-align: justify;padding: 0px 30px;">This device also includes a touch screen control feature for easier user control and interaction. The user interface contained some general sorting information, and also integrated on screen touch button for speed adjustment. On the upper left corner of the screen, there will be number of counts displayed for each category of sorted coins. Additionally, this device will also keep track of the total value of coins sorted in a single round operation, and displayed it under the coin counts. In this way, user can easily know how many change they got after shopping.   </p>
                <p style="text-align: justify;padding: 0px 30px;">Upon every successful detection of coins, the device will also display the detected coin image in the middle of the screen, such that user can easily verify if the device is working correctly.</p>
                <p style="text-align: justify;padding: 0px 30px;"> For this device, user control functionality were incorporated both in button control and touch screen control. There were two touch screen buttons (fast and slow) on the display to let user adjust the running speed of the belt. On the right side of the touch screen, there were four hardware push button to let user control: “stop/resume” of the device, “faster”, “slower” of the coin feeding mechanism, and “quit” the program respectively. The functionalities of the push buttons were also indicated at the left hand side of each push button on the touch screen.  </p>


                <p style="text-align: justify;padding: 30px 30px 5px;"> <b>Trying Different Transportation Approaches</b> </p>
                <p style="text-align: justify;padding: 0px 30px;"><b>Slope vs. Belt</b></p>
                <p style="text-align: justify;padding: 0px 30px;">In the beginning, we had two general concepts of moving coins during the sorting process: </p>
                <li style="text-align: justify;padding: 0px 30px;">1. Using a slope to let the coin sliding through.</li>
                <li style="text-align: justify;padding: 0px 30px;">2. Using a belt to move coins through the system. </li>
                <p style="text-align: justify;padding: 0px 30px;">At the beginning, we generated several hardware structure trying to realize the slope design as our early prototype, we drew <a href="#drawings">the CAD design</a> and generated the corresponding .stl file for 3D printing. The major motivation behind this idea was: Since we needed to do a tons of image processing on the captured frames, it would be better if we could obtain a static back ground for every image we captured. Thus, by using a slope, we could guaranteed that the coin would be always displayed on the same background, and need not to worry much about putting lots of effort on removing the unstable background noises of the image. However, the experiment turned out that, even with the same background every time, the lighting reflected from the slope surface could also effect the counter detection and the image processing. Additionally, by using the slope, we could not guarantee that all the coin would be sliding in the same speed, which introduces extra complexity on designing and adjusting the timing of the following collecting mechanism. </p>
                <p style="text-align: justify;padding: 0px 30px;">Thus, eventually, we decided to make our own conveyor belt to realize the coin transportation functionality. The conveyor belt consisted of a pair of rotating cylinders: one was driven by two continuous rotation servos, and the other was set idle. One of the difficult during the design was to adjust two servos to the same rotation speed, which will be covered in detail in the <a href="#testing">Testing Section</a>.  </p>


                <img class="img-rounded" src="pics/belt.jpg" style="float: right; margin: 50px 50px;" alt="Generic placeholder image" width="360" height="270">
                <p style="text-align: justify;padding: 30px 30px 5px;"> <b>Designing the Conveyor Belt</b> </p>
                <p style="text-align: justify;padding: 0px 30px;">The conveyor belt was made of two cylindrical cardboard, one was driven by two servos, and the other was left idle to support the other end of the belt. The belt was made of a paper all painted with black ink, and the reason for the black ink was to make the edge and background detection much easier for the image processing algorithm.  The speed of the belt was designed to be adjustable, such that user can lowering down the running speed of the machine to make more time for the detection algorithm to generate accurate result when using the device in the non-ideal environment (eg. bad lighting). Since this design were highly modularized, and any part of the design could be easily teared dissembled and readjusted for other operational purposes, thus, even though the moving direction of the belt was usually the same in this design, we also made the belt to support movement in both clockwise and counter-clockwise direction anyway.  </p>


              </div>
          
        </div>
  

    <hr id='drawings'>

      <div style="text-align:center;">
              <h2>Drawings</h2>
                
              <p style="text-align: justify;padding: 0px 30px;">The Coin Sorting Machine is a modularized design that integrates different function block into one device to achieve the target functionality. In our case, “feeding”, “sorting”, and “collecting” mechanism of were design separately. </p>

            <img class="img-rounded" src="pics/coin_transport.png" style="float: right; margin: 0px 50px;" alt="Generic placeholder image" width="200" height="180">
            <div>          
                <p style="text-align: justify; padding-top: 20px; padding-left:50px; padding-right:300px; padding-bottom: 20px "> For the <b>sorting system</b>, we used a rotating plate to “pick up” the coin in the “pocket” shaped container. The coin will fall onto the conveyor belt once it reaches the opening on the top of the mounting surface.  The conceptual drawing of the sorting mechanism looks like the following:   </p>
              </div>

               <p style="text-align: justify;padding: 0px 30px;">For the mechanical structure of this design, we tested several different versions of coin transportation mechanism. Even though in the end we used the conveyor belt to move the coin under the camera, we also tested the option of using inclined slope surface to let the coins sliding under the camera by them self. The CAD design for the mechanical structure was made before converting the file to the printable .stl format. A sample version of the slope design is like the following: </p>

               <img class="img-rounded" src="pics/Frame_V1.png" style="float: center;" alt="Generic placeholder image" width="470" height="500">

               <p style="text-align: justify;padding: 0px 30px;">In order to make sure that the PiCamera always takes the non-distorted picture of the coin, we want the camera lens to be aligned horizontally parallel with the coin surface. Thus, for second version of the “slope” transportation design,  we added a frame that inclines with the same degree as the slope surface to hold the PiCamera above the slope surface. The CAD drawing for the second version of the “slope” design looks like the following:  </p>
               <img class="img-rounded" src="pics/Frame_V2.png" style="float: center;" alt="Generic placeholder image" width="470" height="500">
      </div>

    <hr id='testing'>

      <div style="text-align:center;">
              <h2>Testing</h2>
              <h3 style="text-align: left; padding-left: 30px;">Detection and Classification</h3>
              <p style="text-align: justify;padding: 0px 30px;">The various techniques can be used to recognize and detect the coins of different denomination. The technique such as Circular Hough Transform, Artificial neural networks, heuristics approach has been used for the recognition of coin. The parameters such as size, pattern, material have been used as the parameter to analyze and recognize the denomination of coin. Since the project focus on the real-time image processing, the first thing is the data acquisition. The real time video stream is extracted from PiCamera with a frame rate at 45fps. The size of a single frame is 640*480. For the exposure mode, it is chosen as “sports” mode.</p>
			  <p style="text-align: justify;padding: 0px 30px;">There are several trials for the coin detection software. Many of them works very well on single image, but when the coin move very fast, the processing method turns to be too slow for the servo to take action. Here are steps of coin recognition to and courting the coin.</p>
		      <h3 style="text-align: left; padding-left: 30px; padding-top: 20px">Method 1</h3>
		  	
    	<p style="text-align: justify;padding: 0px 30px;">The method utilized a simple approach with thresholding, morphological operators and contour approximation.</p>
		  
			  <p style="text-align: justify;padding: 0px 30px;">First Step is to apply the Adaptive Thresholding after applying a Gaussian Blur kernel to eliminate the noise that we have in the image.  Note that at that moment the coins have been segmented except for the small noisy inside the center of the coins and also in some places around them.</p>
			  <p style="text-align: justify;padding: 0px 30px;">Second Step is to use the Morphological operators – closing. Morphological operators are used to expand, erode, and otherwise manipulate the pixels of an image. Here, because sometimes the camera can show some handicrafts we will use close morphology operation to ensure that the boundary of the coin is always very close, otherwise, we may find a semicircular coin or something similar. As shown in the image below, some of the unwanted area have been eroded.</p>
   		<p style="text-align: justify;padding: 0px 30px;">After applying the morphological operators, the next step is to find the contour of each coin and then filter the contours having an area smaller or larger than a coin area. The procedure of finding contours in OpenCV can be viewed as the operation of finding connected components and their boundaries. Unfortunately, the method of using either Otsu's threshold or adaptive threshold is highly dependent on the standardization of lighting. In our design, it does not work very well because of thresholding method cannot always filtering out the background, also the reflection of coin may confuse the contour drawing very often.Sample Results are shown below.</p>
		      <p><img class="img-rounded" src="pics/contour.jpeg" alt="Generic placeholder image" style="width:80%;"></p>
		  	  <h3 style="text-align: left; padding-left: 30px; padding-top: 20px">Method 2</h3>
			<p style="text-align: justify;padding: 0px 30px;">Other than differentiating the coin by the area, this method utilized the template matching and feature matching to match different coin with its template. The Template matching is a technique for finding areas of an image that match (are similar) to a template image (patch). The method used for Template matching is to calculate normalized correlation by sliding the source image. The formula is:</p>
		  	<p><img src="pics/formula.png" alt="Generic placeholder image" width="77%" height="69" class="img-rounded" style="width:80%;"></p>
		  <p style="text-align: justify;padding: 0px 30px;">The template matching is a very good method to search for matches between an image patch and an input image, however there are several reasons that it did not fit in our project very well. The most outstanding reason is that the camera resolution is that the coin came in with different angle and reflect the light differently which makes the template matching very inaccurate. To solve the problem, a possible method turns out to be feature matching. </p>

		  <p style="text-align: justify;padding: 0px 30px;">The feature matching tests utilized Brute-Force Matching with ORB Descriptors and BRISK Descriptors. To match features using Descriptors, it starts with loading the images and finding descriptors. Next we create a BFMatcher object with distance measurement cv.NORM_HAMMING and crossCheck is switched on for better results. Then we use Matcher.match() method to get the best matches in two images. We sort them in ascending order of their distances so that best matches (with low distance) come to front. Then we draw only first 10 matches. The result shown below shows a source image on the left, and a template image on the right. </p>
		  <p><img src="pics/featurematch.jpeg" alt="Generic placeholder image" width="76%" height="463" class="img-rounded" style="width:80%;"></p>
		  <p style="text-align: justify;padding: 0px 30px;">As shown in the figure, when illumination condition stays constant, the feature matching works very well. However, in our test case, the variance on lighting condition did confuse feature matching method and did not work well.</p>
		  <h3 style="text-align: left; padding-left: 30px; padding-top: 20px">Method 3 - Final Version</h3>
		  <p style="text-align: justify;padding: 0px 30px;">The method implements HSV thresholding and the Hough Circle transform to find the circular object within the frame.</p>
		  <p style="text-align: justify;padding: 0px 30px;">The first step is transforming the color space to HSV, it was found that the saturation channel of one dime and other coins does have much difference. Through testing, it’s shown that the brass material often has a high saturation value of 70 or higher, iron material has a low saturation value of 30 or lower, background has a saturation value of 0. Therefore, the algorithm counts the pixel that has a high saturation value of 70 or higher, when the number is higher than the threshold, we say a one cent is detected.</p>
		  <p style="text-align: justify;padding: 0px 30px;">The next step implements the Hough Circle transform to find the circular object within the frame. To apply the Hough Circle transform, the first step is to use the canny edge detection to find the edges. Then Hough Circle transform can be used to determine the parameters of a circle when a number of edge points that fall on the perimeter are known. After fitting the circle, the area of the circular object will be calculated to differentiate different coins. After testing, the program can successfully detect one quarter, one dime and 5 cents.</p>


		  <p><img src="pics/table1.jpeg" alt="Generic placeholder image" width="86%" height="128" class="img-rounded" style="width:80%;"></p>

	    <p style="text-align: justify;padding: 0px 30px;">As shown in the table, the accuracy rates for 5 cents and quarter are much lower than others. Through testing, we found out that it was because the calculation on Hough Circle transform takes too much time and many frames are missed when the coin come Within the camera's field of vision. So we make an improvement on the algorithm using multiprocessing thread pool. The improved algorithm works as following flowchart.</p>

		  <p><img src="pics/flowchart.jpg" alt="Generic placeholder image" width="77%" height="486" class="img-rounded" style="width:80%;"></p>
		  
		  <p style="text-align: justify;padding: 0px 30px;">The finalized testing results are shown below.</p>

		  <p><img src="pics/table2.jpeg" alt="Generic placeholder image" width="76%" height="141" class="img-rounded" style="width:80%;"></p>

        <p>&nbsp;</p>

              <h3 style="text-align: left; padding-left: 30px; padding-top: 20px">Hardware and Control Flow</h3>
              <p style="text-align: justify;padding: 0px 30px;"><b>Speed Adjusting:</b></p> 
              <p style="text-align: justify;padding: 0px 30px;">The conveyor belt was driven by two Parallax Continuous Rotation Servos, thus, in order to make the belt running normally, two servos must be adjusted to the same running speed. Since our device also support speed control of the belt, we calibrated multiple pairs of rotation speed in both clockwise and counter-clockwise direction to realize a flexible speed control of the belt. </p>
              <p style="text-align: justify;padding: 0px 30px;"><b>Timing the Collecting Plate:</b></p>    
              <p style="text-align: justify;padding: 0px 30px;">The collecting plate is controlled by a single Parallax Continuous Rotation Servo. Upon receiving the controlling command from the sorting algorithm, the collecting plate will rotate correspondingly to move the correct compartment of the plate right under the conveyor belt. However, in our design, the servo control logic was powered by a RPi PWM library, and we did not introduce any extra external hardware to help calibrate the plate position after every movement, thus, it was crucial to timing every movement correctly otherwise the plate could eventually miss align and fail to catch the coin into the correct compartment. The testing was perform for a great number of trials with empty plate and with different number of coins in the plate. </p>
              <p style="text-align: justify;padding: 0px 30px;">...............</p>
      </div>

    <hr id='result'>

      <div style="text-align:center;">
              <h2>Result</h2>
              <p style="text-align: justify;padding: 0px 30px;">The outcome of this project was pretty satisfying. In the end, we were be able to achieve a relatively high accuracy on the coin classification. This coin sorting machine was able to perform roughly 30 sorts per minutes. One minor drawback of this machine is that it is sensitive to the operational enviroment, especially lighting. However, with the sperated speed control on both convyer belt and the coin feeding plate, user can easily find a optimize running speed of this machine in order to achieve a relatively high accuracy. The user interface of this device also provides a easy and quick view of the sorting outcome for every single classification. The total value of the sorted coins will be shown on the screen for every batch of operation.</p>
      </div>

    <hr>

    <div class="row" style="text-align:center;">
          <h2>Work Distribution</h2>
          <div style="text-align:center;">
              <img class="img-rounded" src="pics/group.jpg" alt="Generic placeholder image" style="width:80%;">
              <h4>Project group picture</h4>
          </div>
          <div class="col-md-6" style="font-size:16px">
              <img class="img-rounded" src="pics/Guangwei.jpg" alt="Generic placeholder image" width="240" height="240">
              <h3>Guangwei Chen</h3>
              <p class="lead">gc535@cornell.edu</p>
              <p>Designed the overall software architecture, and the control flow of the system.</p>
              <p>Designed the pverall hardware structure.</p>
          </div>
          <div class="col-md-6" style="font-size:16px">
              <img class="img-rounded" src="pics/shuheng1.png" alt="Generic placeholder image" width="235" height="264">
              <h3>Shuheng Lin</h3>
              <p class="lead">sl2954@cornell.edu</p>
              <p>Designed the Coin detection software Algorithms, and the testing of all.</div>
      </div>

    <hr>
      <div style="font-size:18px">
          <h2>Parts List</h2>
          <ul>
              <li>Raspberry Pi $35.00</li>
              <li>Raspberry Pi Camera V2 $25.00</li>
              <li>Power Band and Batteries - $15.00</li>
              <li>Servos, Resistors and Wires - Provided in lab</li>
          </ul>
          <h3>Total: $75.00</h3>
      </div>
      <hr>
      <div style="font-size:18px">
          <h2>References</h2>
          <p><a href="https://picamera.readthedocs.io/">PiCamera Document</a><br>
            <a href="https://www.raspberrypi.org/documentation/raspbian/applications/camera.md">PiCamera Configurations</a><br>
            <a href=https://www.parallax.com/sites/default/files/downloads/900-00008-Continuous-Rotation-Servo-Documentation-v2.2.pdf>Parallax Continuous Rotation Servo</a><br>
            <a href="http://www.pygame.org/docs/">pygame documentation</a><br>
            <a href="http://opencvexamples.blogspot.com/2013/10/hough-circle-detection.html">Hough Circle Detection</a><br>
            <a href=" https://docs.opencv.org/3.0-beta/doc/py_tutorials/py_imgproc/py_colorspaces/py_colorspaces.html">OpenCV color space convertion</a><br>
			<a href="https://docs.opencv.org/3.4/d4/dc6/tutorial_py_template_matching.html">Template Matching</a><br>
			<a href="https://docs.opencv.org/3.4/dc/dc3/tutorial_py_matcher.html">Feature Matching</a><br>
			   
          <a href="https://sourceforge.net/p/raspberry-gpio-python/wiki/Home/">R-Pi GPIO Document</a>      </p>
      </div>

    <hr>

      <div class="row">
              <h2>Code Appendix</h2>
              <p>#Guangwei Chen, Shuheng Lin<br>
                #gc535, sl2954<br>
                #This program test the calibrated servo by rotating them in both<br>
                #directions and integrated all the functionality of the coin sorting machine.<br>
                ################################################################<br>
                from picamera.array import PiRGBArray<br>
                from picamera import PiCamera<br>
                import sys, pygame<br>
                import os<br>
                import cv2<br>
                import cv2.cv as cv<br>
                import numpy as np<br>
                import RPi.GPIO as GPIO<br>
                import time<br>
                import math<br>
                from multiprocessing import Pool<br>
                from multiprocessing.dummy import Pool as ThreadPool</p>
              <p>#os.putenv('SDL_VIDEODRIVER','fbcon')   #display on piTFT<br>
                #os.putenv('SDL_FBDEV','/dev/fb1')<br>
                #os.putenv('SDL_MOUSEDRV', 'TSLIB') # Track mouse clicks on piTFT<br>
                #os.putenv('SDL_MOUSEDEV', '/dev/input/touchscreen')</p>
              <p>GPIO.setmode(GPIO.BCM)<br>
                GPIO.setup(17, GPIO.IN,pull_up_down=GPIO.PUD_UP)<br>
                GPIO.setup(22, GPIO.IN,pull_up_down=GPIO.PUD_UP)<br>
                GPIO.setup(23, GPIO.IN,pull_up_down=GPIO.PUD_UP)<br>
                GPIO.setup(27, GPIO.IN,pull_up_down=GPIO.PUD_UP)<br>
                GPIO.setup(5, GPIO.OUT)<br>
                GPIO.setup(6, GPIO.OUT)<br>
                GPIO.setup(19, GPIO.OUT)<br>
                GPIO.setup(26, GPIO.OUT)</p>
              <p>#######################################<br>
                ###     servo control methods       ###<br>
                #######################################</p>
              <p>######### status update #########<br>
                def calculate_frequency(speed):<br>
                frequency = 1000/(speed+pause)     #calculate frequency<br>
                return frequency</p>
              <p>def calcualte_dc(speed):<br>
                dc = 100*speed/(speed+pause)  #calculate duty cycle<br>
                return dc</p>
              <p>######### collector control ###########<br>
                def servo_control(servo, direction, step):</p>
        <p> if(direction == 'ccw'):<br>
                servo.ChangeFrequency(calculate_frequency(1.7))<br>
                servo.start(calcualte_dc(1.7))<br>
                if step == 1:<br>
                print(&quot;ccw, step &quot;+ str(step))<br>
                time.sleep(0.2)<br>
                else:<br>
                print(&quot;ccw, step &quot;+ str(step))<br>
                time.sleep(0.49)<br>
                else:<br>
                servo.ChangeFrequency(calculate_frequency(1.3))<br>
                servo.start(calcualte_dc(1.3))<br>
                if step == 1:<br>
                print(&quot;cw, step &quot;+ str(step))<br>
                time.sleep(0.19)<br>
                else:<br>
                print(&quot;cw, step &quot;+ str(step))<br>
                time.sleep(0.52)<br>
                servo.ChangeFrequency(calculate_frequency(zero_speed))<br>
                servo.ChangeDutyCycle(calcualte_dc(zero_speed))<br>
                servo.stop()<br>
        print(&quot;servo stopped&quot;)</p>
              <p>############# servo objects #############<br>
                class ServoObject:</p>
              <p> def __init__(self, servo):<br>
                self.servo = servo<br>
                self.speed = zero_speed<br>
                self.status = 'stop'<br>
              </p>
              <p> def update(self, speed):<br>
                self.speed = speed<br>
                if speed != zero_speed:<br>
                self.status = 'on'<br>
                else:<br>
                self.status = 'stop'<br>
                self.servo.ChangeFrequency(calculate_frequency(self.speed))<br>
                self.servo.ChangeDutyCycle(calcualte_dc(self.speed))</p>
              <p>class state_handler:</p>
              <p> def __init__(self, servo, init_state):<br>
                self.servo = servo<br>
                self.cur_state = init_state</p>
              <p> def state_transition(self, coin):<br>
                nxt_state = state_dict[coin]<br>
                if nxt_state - self.cur_state == 1 or nxt_state - self.cur_state == -3:<br>
                servo_control(self.servo, &quot;cw&quot;, 1)<br>
                #rotate cw 1 step </p>
              <p> elif nxt_state - self.cur_state == -1 or nxt_state - self.cur_state == 3:<br>
                servo_control(self.servo, &quot;ccw&quot;, 1)<br>
                #rotate ccw 1 step<br>
  <br>
                elif nxt_state - self.cur_state == 2 or self.cur_state - nxt_state == 2:<br>
                servo_control(self.servo, &quot;cw&quot;, 2)<br>
                #rotate cw 2 step<br>
  <br>
                self.cur_state = nxt_state<br>
                print(self.cur_state)<br>
              </p>
              <p>class Belt:</p>
              <p> def __init__(self, servo1, servo2):<br>
                self.servo1 = servo1<br>
                self.servo2 = servo2<br>
                self.run = 0<br>
                self.mode = 'forward'<br>
                self.slow_mode = 0<br>
                self.cw_speed = 1.6<br>
                self.ccw_speed = 1.4<br>
                self.zero_speed = 1.5</p>
              <p> def forward(self):<br>
                self.mode = 'forward'<br>
                self.servo1.ChangeFrequency(calculate_frequency(self.cw_speed))<br>
                self.servo2.ChangeFrequency(calculate_frequency(self.ccw_speed))<br>
                self.servo1.start(calcualte_dc(self.cw_speed))<br>
                self.servo2.start(calcualte_dc(self.ccw_speed))</p>
              <p> def backward(self):<br>
                self.mode = 'backward'<br>
                self.servo1.ChangeFrequency(calculate_frequency(1.34))<br>
                self.servo2.ChangeFrequency(calculate_frequency(self.cw_speed))<br>
                self.servo1.start(calcualte_dc(1.34))<br>
                self.servo2.start(calcualte_dc(self.cw_speed))</p>
              <p> def slow(self):<br>
                if self.mode == 'forward':<br>
                self.servo1.ChangeFrequency(calculate_frequency(self.cw_speed-0.0883))<br>
                self.servo2.ChangeFrequency(calculate_frequency(self.ccw_speed+0.0405))<br>
                self.servo1.ChangeDutyCycle(calcualte_dc(self.cw_speed-0.0883))<br>
                self.servo2.ChangeDutyCycle(calcualte_dc(self.ccw_speed+0.0405))<br>
                else:<br>
                self.servo1.ChangeFrequency(calculate_frequency(1.34+0.03))<br>
                self.servo2.ChangeFrequency(calculate_frequency(self.cw_speed-0.041))<br>
                self.servo1.ChangeDutyCycle(calcualte_dc(1.34+0.03))<br>
                self.servo2.ChangeDutyCycle(calcualte_dc(self.cw_speed-0.041))</p>
              <p> def stop(self):<br>
                self.servo1.ChangeFrequency(calculate_frequency(self.zero_speed))<br>
                self.servo2.ChangeFrequency(calculate_frequency(self.zero_speed))<br>
                self.servo1.ChangeDutyCycle(calcualte_dc(self.zero_speed))<br>
                self.servo2.ChangeDutyCycle(calcualte_dc(self.zero_speed))<br>
                self.servo1.stop()<br>
                self.servo2.stop()</p>
              <p>&nbsp;</p>
              <p>###########################################<br>
                ###     END servo control methods       ###<br>
                ###########################################</p>
              <p>####################################<br>
                ######### PiTFT Screen #############<br>
                ####################################</p>
              <p>########## screen methods ##########<br>
                def touchscreen_polling(level):<br>
                time.sleep(0.2)<br>
                for event in pygame.event.get():<br>
                if event.type == pygame.QUIT: quit()<br>
                if(event.type is pygame.MOUSEBUTTONDOWN):<br>
                pos = pygame.mouse.get_pos()<br>
                elif(event.type is pygame.MOUSEBUTTONUP):<br>
                pos = pygame.mouse.get_pos()<br>
                pos = pygame.mouse.get_pos()<br>
                x,y = pos<br>
                if level == 1:<br>
                if 40&lt;=x&lt;=80 and 200&lt;=y&lt;=240 :<br>
                quit()<br>
                if 220&lt;=x&lt;=260 and 200&lt;=y&lt;=240:<br>
                on = 1<br>
                level = 2<br>
                update_screen(level, 'wait')   # init second lvl display<br>
  <br>
  <br>
                elif level == 2:<br>
                if 116&lt;=x&lt;=164 and 210&lt;=y&lt;=230:     # slow down belt<br>
                print('belt slow')<br>
                belt.slow_mode = 1<br>
                belt.slow()<br>
                if 186&lt;=x&lt;=234 and 210&lt;y&lt;=230:      #speed up belt<br>
                print('belt fast')<br>
                belt.slow_mode = 0<br>
                if(belt.mode == 'forward'):<br>
                belt.forward()<br>
                else:<br>
                belt.backward()<br>
                if 16&lt;=x&lt;=64 and 210&lt;y&lt;=230:<br>
                print('back')<br>
                return level</p>
              <p>def update_screen(level, coin):<br>
                screen.fill(black)<br>
                if level ==2:<br>
                # coins<br>
                for coin_text, coin_pos in Coins.items():<br>
                coin_surface = my_font.render(coin_text, True, WHITE)<br>
                rect = coin_surface.get_rect(center=coin_pos)<br>
                screen.blit(coin_surface, rect)<br>
                pygame.draw.polygon(screen, GREEN, ((305, 42), (315, 47), (305, 52))) <br>
                pygame.draw.polygon(screen, GREEN, ((305, 106), (315, 111), (305, 116))) <br>
                pygame.draw.polygon(screen, GREEN, ((305, 164), (315, 169), (305, 174))) <br>
                pygame.draw.polygon(screen, GREEN, ((305, 228), (315, 233), (305, 238))) </p>
              <p> # value counts:<br>
                for value_index, value_pos in value_display.items():<br>
                value_surface = my_font.render(str(value_count[value_index]), True, WHITE)<br>
                rect = value_surface.get_rect(center=value_pos)<br>
                screen.blit(value_surface, rect)</p>
              <p> totalvalue_text_surface = total_font.render('Total $:', True, GREEN)<br>
                rect = totalvalue_text_surface.get_rect(center=(20, 90))<br>
                screen.blit(totalvalue_text_surface, rect)<br>
                totalvalue_surface = total_font.render(str(total_value), True, GREEN)<br>
                rect = totalvalue_surface.get_rect(center=(55, 90))<br>
                screen.blit(totalvalue_surface, rect)<br>
  <br>
                # coin image display <br>
                if coin == '1 cent':<br>
                coin_rect = onecent.get_rect()<br>
                coin_rect = coin_rect.move(115, 70)<br>
                screen.blit(onecent, coin_rect)<br>
                elif coin == '5 cents':<br>
                coin_rect = fivecent.get_rect()<br>
                coin_rect = coin_rect.move(105, 68)<br>
                screen.blit(fivecent, coin_rect)<br>
                elif coin == 'dime':<br>
                coin_rect = dime.get_rect()<br>
                coin_rect = coin_rect.move(118, 72)<br>
                screen.blit(dime, coin_rect)<br>
                elif coin == 'quarter':<br>
                coin_rect = quarter.get_rect()<br>
                coin_rect = coin_rect.move(110, 65)<br>
                screen.blit(quarter, coin_rect)<br>
                else:<br>
                coin_rect = wait_input.get_rect()<br>
                coin_rect = coin_rect.move(105, 60)<br>
                screen.blit(wait_input, coin_rect)<br>
              </p>
              <p> # program controls:<br>
                for belt_text, belt_pos in program_controller.items():<br>
                belt_surface = my_font.render(belt_text, True, WHITE)<br>
                rect = belt_surface.get_rect(center=belt_pos)<br>
                screen.blit(belt_surface, rect)</p>
              <p> for button_text, button_pos in button_control.items():<br>
                button_surface = my_font.render(button_text, True, WHITE)<br>
                rect = button_surface.get_rect(center=button_pos)<br>
                pygame.draw.rect(screen, cyan, (button_pos[0]-24, button_pos[1]-10, 48, 20)) <br>
                screen.blit(button_surface, rect)<br>
                pygame.draw.rect(screen, crimson, (40-24, 220-10, 48, 20))<br>
                button_surface = my_font.render('Back', True, black)<br>
                rect = button_surface.get_rect(center=(40, 220)) <br>
                screen.blit(button_surface, rect)</p>
              <p> if level ==1:<br>
                for my_text, text_pos in my_button.items():<br>
                text_surface = my_font.render(my_text, True, WHITE)<br>
                rect = text_surface.get_rect(center=text_pos)<br>
                screen.blit(text_surface, rect)</p>
              <p> pygame.display.flip()</p>
              <p>###########################################<br>
                ######### END of PiTFT Screen #############<br>
                ###########################################<br>
              </p>
              <p>############################################<br>
                ###   callback subroutine definition     ###<br>
                ############################################</p>
              <p>def GPIO17_callback(channel):           #resume or stop coin_rotate servo<br>
                if(coin_rotator.status=='stop'):<br>
                coin_rotator.update(ccw_speed)<br>
                belt.backward()<br>
                else:<br>
                coin_rotator.update(zero_speed)<br>
                belt.stop()<br>
              </p>
              <p>def GPIO22_callback(channel):           #speed up <br>
                # speed up rotator<br>
                if(coin_rotator.status!='stop'):<br>
                if(coin_rotator.speed &lt; 1.7):<br>
                global ccw_speed<br>
                ccw_speed += 0.02<br>
                coin_rotator.update(ccw_speed)</p>
              <p> '''<br>
                # unused &lt;for changing belt direction&gt; <br>
                if(belt.mode=='forward'):<br>
                belt.stop()<br>
                time.sleep(0.3)<br>
                belt.backward()<br>
                else:<br>
                belt.stop()<br>
                time.sleep(0.3)<br>
                belt.forward()<br>
                '''<br>
              </p>
              <p>def GPIO23_callback(channel):           #slow down<br>
                # slow down rotator<br>
                if(coin_rotator.status!='stop'):<br>
                if(coin_rotator.speed &gt; 1.52):<br>
                global ccw_speed<br>
                ccw_speed -= 0.02<br>
                coin_rotator.update(ccw_speed)<br>
              </p>
              <p>def GPIO27_callback(channel):           #exit program<br>
                coin_rotator.servo.stop()<br>
                coin_collector.stop()<br>
                belt.stop()<br>
                file = open(&quot;state_log.txt&quot;, &quot;w&quot;)<br>
                file.write(str(sh.cur_state))<br>
                file.close<br>
                GPIO.cleanup() <br>
                quit()</p>
              <p>################################################<br>
                ###   END callback subroutine definition     ###<br>
                ################################################<br>
              </p>
              <p>################################################<br>
                ###       Program initialization stage       ###<br>
                ################################################<br>
              </p>
              <p>###### PiCemara Init ###########<br>
                # initialize the camera and grab a reference to the raw camera capture<br>
                camera = PiCamera()<br>
                camera.resolution = (640, 480)<br>
                camera.framerate = 45<br>
                camera.exposure_mode='sports'<br>
                rawCapture = PiRGBArray(camera, size=(640, 480))</p>
              <p># allow the camera to warmup<br>
                time.sleep(0.1)<br>
                start = time.time()<br>
                tot_radius = []<br>
                count = 0<br>
                saturation = np.array([])</p>
              <p>############# PiTFT init #############<br>
                pygame.init()<br>
                pygame.mouse.set_visible(True)<br>
                size = width, height = 320, 240<br>
                screen = pygame.display.set_mode(size)<br>
                ######## parameter init<br>
                WHITE = 255, 255, 255<br>
                black = 0, 0, 0<br>
                GREEN = 57, 255, 20<br>
                cyan = 0, 139, 139<br>
                crimson = 220,20,60<br>
                state_dict = {'1 cent':0, '5 cents':1, 'dime':2, 'quarter':3}<br>
                value_index_dict = {0:'1 cent', 1:'5 cents', 2:'dime', 3:'quarter'}<br>
                ############# asset #############<br>
                my_font = pygame.font.Font(None, 15)<br>
                total_font = pygame.font.Font(None, 18)<br>
                Coins = {'Quarters:':(23,10),<br>
                'Dime:':(23,30),<br>
                '5 cents:':(23,50),<br>
                '1 cent:':(23,70)}</p>
              <p>value_display = { 3:(53,10),<br>
                2:(53,30),<br>
                1:(53,50),<br>
                0:(53,70)}<br>
                value_count = [0, 0, 0, 0]<br>
                coin_value = [0.01, 0.05, 0.1, 0.25]<br>
                total_value = 0<br>
                my_button = {'quit':(60,220),'start':(240,220)}<br>
                program_controller={'Stop':(290,47),<br>
                'Faster':(285,111),<br>
                'Slower':(285,169),<br>
                'Quit':(290, 233)}<br>
                button_control = {'back':(40, 220),<br>
                'belt slow':(140, 220),<br>
                'belt fast':(210, 220 )}<br>
              </p>
              <p> # coin asset<br>
                onecent = pygame.image.load(&quot;1cent.bmp&quot;)<br>
                fivecent = pygame.image.load(&quot;5cents.bmp&quot;)<br>
                dime = pygame.image.load(&quot;dime.bmp&quot;)<br>
                quarter = pygame.image.load(&quot;quarter.bmp&quot;)<br>
                wait_input = pygame.image.load(&quot;input.bmp&quot;)<br>
              </p>
              <p>############ initialize servos ############<br>
                zero_speed = 1.5   #set the static pule duration<br>
                cw_speed = 1.46<br>
                ccw_speed = 1.54<br>
                pause = 20         #set pause duration<br>
                state_dict = {'1 cent':0, '5 cents':1, 'dime':2, 'quarter':3}<br>
              </p>
              <p>############ initialize collector state ############<br>
                try: <br>
                file = open(&quot;state_log.txt&quot;, &quot;r&quot;)<br>
                state = int(file.read())<br>
                file.close()<br>
                except:<br>
                file = open(&quot;state_log.txt&quot;, &quot;w&quot;)<br>
                file.write(&quot;0&quot;)<br>
                state = 0<br>
                file.close()</p>
              <p>############# feeder servo ##########<br>
                coin_rotator = ServoObject(GPIO.PWM(5, calculate_frequency(zero_speed)))<br>
                coin_rotator.servo.start(calcualte_dc(zero_speed))</p>
              <p>############# collector servo ##########<br>
                coin_collector = GPIO.PWM(6, calculate_frequency(zero_speed))<br>
                #coin_collector.start(calcualte_dc(zero_speed))</p>
              <p>############ belt servos ###############<br>
                belt_servo1 = GPIO.PWM(19, calculate_frequency(zero_speed))<br>
                belt_servo2 = GPIO.PWM(26, calculate_frequency(zero_speed))<br>
                time.sleep(1)<br>
              </p>
              <p>###### main function ########<br>
                GPIO.add_event_detect(17,GPIO.FALLING,callback=GPIO17_callback,bouncetime=300)<br>
                GPIO.add_event_detect(22,GPIO.FALLING,callback=GPIO22_callback,bouncetime=300)<br>
                GPIO.add_event_detect(23,GPIO.FALLING,callback=GPIO23_callback,bouncetime=300)<br>
                GPIO.add_event_detect(27,GPIO.FALLING,callback=GPIO27_callback,bouncetime=300)</p>
              <p>coin_rotator.update(ccw_speed)<br>
                belt = Belt(belt_servo1, belt_servo2)<br>
                belt.backward()</p>
              <p>sh = state_handler(coin_collector, state)<br>
              </p>
              <p>on =0<br>
                level=2<br>
                prompt = 'enter coin'<br>
                update_screen(level, 'wait')<br>
              </p>
              <p>#####save image<br>
                frame_list = []<br>
                tot_radius_list = []<br>
                saturation_high_list = []<br>
              </p>
              <p>def detect_circle(img):</p>
              <p> gry = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)<br>
                gry = cv2.medianBlur(gry, 3)<br>
                rows = gry.shape[0]<br>
  <br>
                hsv1=cv2.cvtColor(img,cv2.COLOR_BGR2HSV)<br>
                saturation1=np.array(hsv1[:,:,1].flatten())<br>
                circles = cv2.HoughCircles(gry, cv.CV_HOUGH_GRADIENT, 1.2, rows / 8,<br>
                param1=50, param2=80,<br>
                minRadius=40, maxRadius=150)<br>
  <br>
                count =0<br>
                tot_radius=[]<br>
                if circles is not None:<br>
                circles = np.uint16(np.around(circles))<br>
                for i in circles[0, :]:<br>
                center = (i[0], i[1])<br>
                radius = i[2] <br>
                area = math.pow(radius,2)*math.pi<br>
                if area &gt; 15000:<br>
                tot_radius=np.append(tot_radius,area)<br>
                tot_radius_list.append(tot_radius)</p>
              <p> saturation_high1 = cv2.countNonZero(cv2.inRange(saturation1,70,255))<br>
                saturation_high_list.append(saturation_high1)<br>
                else:<br>
                return -1<br>
              </p>
              <p>one_flag = 0<br>
                while(1): <br>
                # capture frames from the camera<br>
                flag =1<br>
                for frame in camera.capture_continuous(rawCapture, format='bgr', use_video_port=True):<br>
                # grab the raw NumPy array representing the image, then initialize the timestamp<br>
                # and occupied/unoccupied text<br>
                touchscreen_polling(level)<br>
                image = frame.array<br>
                if flag ==1:<br>
                hsv=cv2.cvtColor(image,cv2.COLOR_BGR2HSV)<br>
                saturation=np.array(hsv[:,:,1].flatten())<br>
                saturation_low = cv2.countNonZero(cv2.inRange(saturation,0,10))<br>
                saturation_high = cv2.countNonZero(cv2.inRange(saturation,70,255))<br>
                #cv2.imshow(&quot;Frame&quot;, image)<br>
                if saturation_high&gt;6000:<br>
                print('one cent')<br>
                coin = '1 cent'<br>
                sh.state_transition('1 cent')<br>
                time.sleep(0.8)<br>
                elif saturation_low &lt; 220000:<br>
                saturation_high_list =[]<br>
                frame_list =[]<br>
                frame_list.append(image)<br>
                saturation_high_list.append(saturation_high)<br>
                flag = 2<br>
                else:<br>
                frame_list=[]<br>
                flag = 1<br>
                #cv2.imshow(&quot;Frame&quot;, image)<br>
                elif flag ==2:<br>
                frame_list.append(image)<br>
                if (max(saturation_high_list)&gt; 5000):<br>
                print('1 cent')<br>
                coin = '1 cent'<br>
                sh.state_transition('1 cent')<br>
                saturation_high_list = []<br>
                frame_list = []<br>
                flag =1<br>
                elif(len(frame_list) == 4):<br>
                tot_radius_list = []<br>
                pool = ThreadPool()<br>
                pool.map(detect_circle, frame_list)<br>
                pool.close()<br>
                pool.join()<br>
                flag = 1<br>
                frame_list = []</p>
              <p> if (max(saturation_high_list)&gt; 5000):<br>
                print('1 cent')<br>
                coin = '1 cent'<br>
                sh.state_transition('1 cent')<br>
                saturation_high_list = []<br>
                frame_list = []<br>
                flag =1<br>
                elif(len(tot_radius_list) &gt;=1):<br>
                print(tot_radius_list)<br>
                print(saturation_high_list)<br>
                r=np.median(tot_radius_list)<br>
                #cv2.imshow(&quot;Frame&quot;, image)<br>
                if 28000&lt;r&lt;38000:<br>
                print('5 cents')<br>
                coin = '5 cents'<br>
                sh.state_transition('5 cents')<br>
                elif 38000&lt;=r&lt;50000:<br>
                print('quarter')<br>
                coin = 'quarter'<br>
                sh.state_transition('quarter')<br>
                elif 15000&lt;r:&lt;=28000:<br>
                print('1 dime')<br>
                coin = 'dime'<br>
                sh.state_transition('dime')<br>
                else:<br>
                coin=None<br>
                flag=1<br>
                frame_list = [] </p>
              <p># if coin disappear in frame, we count the number of coin<br>
                if coin is not None:<br>
                value_count[state_dict[coin]] += 1<br>
                total_value += coin_value[state_dict[coin]]<br>
                update_screen(level, coin)<br>
              </p>
              <p> key = cv2.waitKey(1) &amp; 0xFF<br>
                # clear the stream in preparation for the next frame<br>
                rawCapture.truncate(0)<br>
  <br>
                # if the `q` key was pressed, break from the loop<br>
                if key == ord(&quot;q&quot;):<br>
                break</p>
              <p>&nbsp;</p>
              <pre>&nbsp;</pre>
      </div>

    </div><!-- /.container -->




    <!-- Bootstrap core JavaScript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.12.4/jquery.min.js"></script>
    <script>window.jQuery || document.write('<script src="../../assets/js/vendor/jquery.min.js"><\/script>')</script>
    <script src="dist/js/bootstrap.min.js"></script>
    <!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->
    <!-- <script src="../../assets/js/ie10-viewport-bug-workaround.js"></script> -->
  </body>
</html>
